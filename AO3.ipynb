{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aff29d5",
   "metadata": {},
   "source": [
    "# AO3 scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c491d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399229a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AO3_soup = []\n",
    "\n",
    "for x in range(1, 101):\n",
    "    fanfic_page = BeautifulSoup(open(f'AO3 htmls/AO3_Page{x}.html'), 'html.parser')\n",
    "    fanfic_page.prettify()\n",
    "    AO3_soup.append(fanfic_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243c032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archiveofourown.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90fa58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWebsiteAsSoup(url):\n",
    "\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        story_html = response.read()\n",
    "    \n",
    "    story_soup = BeautifulSoup(story_html, 'html.parser')\n",
    "    with open('story.html', 'w') as new_file:\n",
    "        new_file.write(str(story_soup))\n",
    "        \n",
    "    return story_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b309794",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = []\n",
    "fanfics = []\n",
    "relationship = []\n",
    "character = []\n",
    "mix_fandom = []\n",
    "\n",
    "for x in range(len(AO3_soup)):\n",
    "    for titles in AO3_soup[x].find_all('li', role = 'article'):\n",
    "        fanfic = {}\n",
    "        title = titles.find('a').get_text()\n",
    "        fanfic['title'] = title\n",
    "        \n",
    "        url_tail = titles.find('a').get('href')\n",
    "        link = url + url_tail\n",
    "        stories.append([title, link])\n",
    "        \n",
    "        fandom = titles.find_all('h5', class_ = 'fandoms heading')\n",
    "        fandoms = [tag.get_text().strip() for tag in fandom]\n",
    "        fanfic['mixed fandom'] = fandoms\n",
    "        mix_fandom.append(fandoms)\n",
    "        \n",
    "        relationships = titles.find_all('li', class_ = 'relationships')\n",
    "        ships = [tag.get_text().strip() for tag in relationships]\n",
    "        fanfic['ships'] = ships\n",
    "        \n",
    "        char = titles.find_all('li', class_ = 'characters')\n",
    "        characters = [tag.get_text() for tag in char]\n",
    "        fanfic['characters'] = (characters)\n",
    "        \n",
    "        try:\n",
    "            hits = titles.find('dd', 'hits').get_text()\n",
    "        except:\n",
    "            hits = None\n",
    "        fanfic['hits'] = hits\n",
    "        \n",
    "        try:\n",
    "            kudos = titles.find('dd', 'kudos').get_text()\n",
    "        except:\n",
    "            kudos = None\n",
    "        fanfic['kudos'] = kudos\n",
    "        \n",
    "        try:\n",
    "            fic_soup = getWebsiteAsSoup(link)\n",
    "            fic_soup.prettify()\n",
    "            for info in fic_soup:\n",
    "                published = info.find('dd', class_ = 'published').get_text()\n",
    "                fanfic['published'] = published\n",
    "                relationship.append([ships, published])\n",
    "                character.append([characters, published])\n",
    "        except:\n",
    "            published = titles.find('p', class_ = 'datetime').get_text()\n",
    "            fanfic['published'] = published\n",
    "            character.append([characters, published])\n",
    "            relationship.append([ships, published])\n",
    "        fanfics.append(fanfic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c59fe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>mixed fandom</th>\n",
       "      <th>ships</th>\n",
       "      <th>characters</th>\n",
       "      <th>hits</th>\n",
       "      <th>kudos</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Purple poison flames meet Blue fire</td>\n",
       "      <td>[Fandoms:\\n鬼滅の刃 | Demon Slayer: Kimetsu no Yai...</td>\n",
       "      <td>[Dabi | Todoroki Touya &amp; Kochou Shinobu]</td>\n",
       "      <td>[Dabi | Todoroki Touya, Kochou Shinobu]</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>02 Apr 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuck With Babysitter Duty</td>\n",
       "      <td>[Fandoms:\\n僕のヒーローアカデミア | Boku no Hero Academia...</td>\n",
       "      <td>[Dazai Osamu/Nakahara Chuuya (Bungou Stray Dogs)]</td>\n",
       "      <td>[Midoriya Izuku, Dazai Osamu (Bungou Stray Dog...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>02 Apr 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Power in UA!!!</td>\n",
       "      <td>[Fandoms:\\nChainsaw Man (Anime), 僕のヒーローアカデミア |...</td>\n",
       "      <td>[Bakugou Katsuki/Power, Power &amp; Class 1-A]</td>\n",
       "      <td>[Power (Chainsaw Man), Ashido Mina, Iida Tenya...</td>\n",
       "      <td>508</td>\n",
       "      <td>7</td>\n",
       "      <td>02 Apr 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balance and Bondeds</td>\n",
       "      <td>[Fandoms:\\n僕のヒーローアカデミア | Boku no Hero Academia...</td>\n",
       "      <td>[Aizawa Shouta | Eraserhead/Yamada Hizashi | P...</td>\n",
       "      <td>[Midoriya Izuku, Midoriya Inko, Bakugou Katsuk...</td>\n",
       "      <td>11924</td>\n",
       "      <td>481</td>\n",
       "      <td>02 Apr 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can't Hold Our Babies</td>\n",
       "      <td>[Fandoms:\\n僕のヒーローアカデミア | Boku no Hero Academia...</td>\n",
       "      <td>[Bakugou Katsuki/Midoriya Izuku/Uraraka Ochako...</td>\n",
       "      <td>[Bakugou Katsuki, Uraraka Ochako, Midoriya Izuku]</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>02 Apr 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0  Purple poison flames meet Blue fire   \n",
       "1           Stuck With Babysitter Duty   \n",
       "2                       Power in UA!!!   \n",
       "3                  Balance and Bondeds   \n",
       "4                Can't Hold Our Babies   \n",
       "\n",
       "                                        mixed fandom  \\\n",
       "0  [Fandoms:\\n鬼滅の刃 | Demon Slayer: Kimetsu no Yai...   \n",
       "1  [Fandoms:\\n僕のヒーローアカデミア | Boku no Hero Academia...   \n",
       "2  [Fandoms:\\nChainsaw Man (Anime), 僕のヒーローアカデミア |...   \n",
       "3  [Fandoms:\\n僕のヒーローアカデミア | Boku no Hero Academia...   \n",
       "4  [Fandoms:\\n僕のヒーローアカデミア | Boku no Hero Academia...   \n",
       "\n",
       "                                               ships  \\\n",
       "0           [Dabi | Todoroki Touya & Kochou Shinobu]   \n",
       "1  [Dazai Osamu/Nakahara Chuuya (Bungou Stray Dogs)]   \n",
       "2         [Bakugou Katsuki/Power, Power & Class 1-A]   \n",
       "3  [Aizawa Shouta | Eraserhead/Yamada Hizashi | P...   \n",
       "4  [Bakugou Katsuki/Midoriya Izuku/Uraraka Ochako...   \n",
       "\n",
       "                                          characters   hits kudos    published  \n",
       "0            [Dabi | Todoroki Touya, Kochou Shinobu]      0  None  02 Apr 2023  \n",
       "1  [Midoriya Izuku, Dazai Osamu (Bungou Stray Dog...      0  None  02 Apr 2023  \n",
       "2  [Power (Chainsaw Man), Ashido Mina, Iida Tenya...    508     7  02 Apr 2023  \n",
       "3  [Midoriya Izuku, Midoriya Inko, Bakugou Katsuk...  11924   481  02 Apr 2023  \n",
       "4  [Bakugou Katsuki, Uraraka Ochako, Midoriya Izuku]      0  None  02 Apr 2023  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fanfics_df = pd.DataFrame.from_dict(fanfics, orient = 'columns')\n",
    "fanfics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96dda902",
   "metadata": {},
   "outputs": [],
   "source": [
    "fanfics_df.to_csv(\"AO3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c990fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d52f476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shipings = pd.DataFrame(relationship)\n",
    "shipings.columns = ['ships', 'dates']\n",
    "ships = shipings[219:]\n",
    "ships = ships.explode('ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e40a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ships.to_csv(\"shipsviadate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd76bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "character.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6ad349",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.DataFrame(character)\n",
    "characters.columns = ['names', 'dates']\n",
    "characters = characters[65:]\n",
    "characters = characters.explode('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92fd761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.to_csv('charactersviadate.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcffdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
